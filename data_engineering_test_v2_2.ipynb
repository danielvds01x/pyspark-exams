{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVSy2BqsaSkj"
   },
   "source": [
    "# Setup Geral\n",
    "\n",
    "Se estiver executando este exercício no Google Colab, execute as próximas duas células. \n",
    "\n",
    "Caso esteja executando localmente, não é necessário executar mas certifique-se de que o **pyspark** está instalado e configurado em sua máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NHPXuknHZ5Az"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Instal Java\n",
    "# apt-get update && apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "# Install PySpark\n",
    "# pip install -q pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# Create dir for data_cleansed\n",
    "rm -rf bases_limpas\n",
    "mkdir bases_limpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4dY12q0raXtc"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZZMC5QPae-Z"
   },
   "source": [
    "# Teste\n",
    "\n",
    "O teste a ser realizado é composto de 3 partes:\n",
    "\n",
    "- um exercício de programação em Python\n",
    "- alguns exercícios de programação em SQL\n",
    "- alguns exercícios de programação com PySpark\n",
    "\n",
    "Você pode escolher qual das partes do exercício vai fazer primeiro. Todo o exercício deve ser completado no período de 90 minutos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUB8S5fKciHv"
   },
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "2F8f5Z1scgUP"
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "nomes_alunos = [\n",
    "    ('Maria', 1),\n",
    "    ('João', 2),\n",
    "    ('Pedro', 3),\n",
    "    ('Gabriella', 4),\n",
    "    ('Giovana', 5),\n",
    "    ('Arthur', 6)\n",
    "]\n",
    "\n",
    "notas_alunos = {\n",
    "    1: 9.5,\n",
    "    2: 5.1,\n",
    "    3: 8.7,\n",
    "    4: 7.1,\n",
    "    5: 4.8,\n",
    "    6: 6.3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApIQ4JqjcsnC"
   },
   "source": [
    "Implemente uma função que recebe uma lista de nomes de alunos, um dicionário de notas dos mesmo, sendo que essas estruturas se relacionam por um ID.\n",
    "\n",
    "A função deve retornar em ordem alfabética, o nome dos alunos que obtiveram notas maior ou igual de uma nota de corte informada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "ISnDoCWucpHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arthur\n",
      "Gabriella\n",
      "Maria\n",
      "Pedro\n"
     ]
    }
   ],
   "source": [
    "def filtra_alunos_acima_corte(alunos, notas, nota_corte):\n",
    "\n",
    "    alunos = sorted(dict(alunos).items(), key=lambda kv: (kv[0], kv[1]))\n",
    "    alunos = dict(alunos)\n",
    "\n",
    "    for aluno in alunos:\n",
    "        if notas_alunos.get(alunos[aluno]) >= nota_corte:\n",
    "            print(aluno)\n",
    "    \n",
    "filtra_alunos_acima_corte(nomes_alunos, notas_alunos, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iYs_aWqdXrh"
   },
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbIq-A9-gXdw"
   },
   "source": [
    "**Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DOG9FO83dlSe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘bases_teste’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1039  100  1039    0     0   8056      0 --:--:-- --:--:-- --:--:--  8117\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  533k  100  533k    0     0  2282k      0 --:--:-- --:--:-- --:--:-- 2291k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211k  100  211k    0     0  1547k      0 --:--:-- --:--:-- --:--:-- 1553k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir bases_teste\n",
    "curl https://raw.githubusercontent.com/A3Data/bases_testes/main/bases_teste/produtos.csv -o bases_teste/produtos.csv\n",
    "curl https://raw.githubusercontent.com/A3Data/bases_testes/main/bases_teste/vendas.csv -o bases_teste/vendas.csv\n",
    "curl https://raw.githubusercontent.com/A3Data/bases_testes/main/bases_teste/usuarios.csv -o bases_teste/usuarios.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/31 02:58:23 WARN Utils: Your hostname, LNVTP01X resolves to a loopback address: 127.0.1.1; using 172.29.227.219 instead (on interface eth0)\n",
      "22/07/31 02:58:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/31 02:58:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/07/31 02:58:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/31 02:58:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Encontrando o Spark Local\n",
    "import findspark\n",
    "findspark.init('/usr/local/spark/spark-3.3.0-bin-hadoop3/')\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AtividadeSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kHkTwPZmfV2t"
   },
   "outputs": [],
   "source": [
    "# Setup Spark Session\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.appName(\"AtividadeSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3kb1a6CwgSVd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cria_tabela(path, nome_tabela):\n",
    "    df = spark.read.csv(path, inferSchema=True, header=True)\n",
    "    df.createOrReplaceTempView(nome_tabela)\n",
    "    return df\n",
    "\n",
    "usuarios = cria_tabela(\"bases_teste/usuarios.csv\", \"usuarios\")\n",
    "produtos = cria_tabela(\"bases_teste/produtos.csv\", \"produtos\")\n",
    "vendas = cria_tabela(\"bases_teste/vendas.csv\", \"vendas\")\n",
    "\n",
    "type(usuarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N5gLPYEg27q"
   },
   "source": [
    "**Função para execução de queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HtpEu2utg5Pb"
   },
   "outputs": [],
   "source": [
    "def q(query, n=30):\n",
    "    return spark.sql(query).show(n=n, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s84UzyTqg9lH"
   },
   "source": [
    "Para executar alguma consulta, basta colocar seu código sql dentro da função q como no exemplo abaixo:\n",
    "\n",
    "```python\n",
    "q(\"\"\"\n",
    "    SELECT *\n",
    "    FROM usuarios\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "e o resultado será exibido na tela.\n",
    "\n",
    "---\n",
    "\n",
    "Nesta parte da atividade, você vai trabalhar com três tabelas:\n",
    "\n",
    "- produtos\n",
    "- usuarios\n",
    "- vendas\n",
    "\n",
    "Use-as para responder às perguntas a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Checagens\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+------------------+------------------+-------------------+\n",
      "|cod_usuario|data_cadastro      |faixa_etaria      |cidade            |estado             |\n",
      "+-----------+-------------------+------------------+------------------+-------------------+\n",
      "|28         |2020-01-19 00:00:00|Entre 22 a 27 anos|Sertão            |Rio Grande do Sul  |\n",
      "|69         |2020-07-24 00:00:00|Entre 16 a 21 anos|São Romão         |Minas Gerais       |\n",
      "|89         |2020-03-18 00:00:00|Mais de 70 anos   |Campestre da Serra|Rio Grande do Sul  |\n",
      "|124        |2020-12-17 00:00:00|Entre 28 a 36 anos|Curral de Dentro  |Minas Gerais       |\n",
      "|153        |2020-02-29 00:00:00|Entre 37 a 49 anos|Santiago          |Rio Grande do Sul  |\n",
      "|156        |2019-03-18 00:00:00|Entre 16 a 21 anos|Porto Nacional    |Tocantins          |\n",
      "|176        |2021-03-19 00:00:00|Entre 28 a 36 anos|Guanambi          |Bahia              |\n",
      "|185        |2021-03-11 00:00:00|Entre 16 a 21 anos|Martins           |Rio Grande do Norte|\n",
      "|191        |2021-01-16 00:00:00|Entre 37 a 49 anos|Icatu             |Maranhão           |\n",
      "|441        |2020-03-16 00:00:00|Entre 28 a 36 anos|Buriti Bravo      |Maranhão           |\n",
      "+-----------+-------------------+------------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tabela de Usuários\n",
    "q(\"\"\"\n",
    "    SELECT * FROM usuarios\n",
    "    WHERE cod_usuario IS NOT NULL\n",
    "    ORDER BY cod_usuario\n",
    "\"\"\",n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------------+----------+-------+\n",
      "|cod_usuario|cod_produto|data_compra        |quantidade|valor  |\n",
      "+-----------+-----------+-------------------+----------+-------+\n",
      "|927        |10         |2020-10-19 00:00:00|4         |2799.6 |\n",
      "|1544       |10         |2021-03-28 00:00:00|2         |1399.8 |\n",
      "|2833       |2          |2020-09-13 00:00:00|20        |26915.6|\n",
      "|2253       |14         |2021-06-21 00:00:00|1         |138.99 |\n",
      "|1724       |10         |2021-07-10 00:00:00|6         |4199.4 |\n",
      "|1534       |5          |2019-10-17 00:00:00|19        |8303.0 |\n",
      "|1977       |14         |2020-05-08 00:00:00|2         |277.98 |\n",
      "|1916       |3          |2020-12-01 00:00:00|14        |28693.0|\n",
      "|2446       |1          |2021-06-02 00:00:00|17        |78045.3|\n",
      "|2041       |4          |2021-07-25 00:00:00|19        |1119.1 |\n",
      "+-----------+-----------+-------------------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tabela de Vendas\n",
    "q(\"\"\"\n",
    "    SELECT * FROM vendas\n",
    "\"\"\",n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+-----+\n",
      "|table_name|column_name|profiling     |value|\n",
      "+----------+-----------+--------------+-----+\n",
      "|usuarios  |-          |row_count     |5570 |\n",
      "|usuarios  |cod_usuario|count_distinct|3406 |\n",
      "|usuarios  |cod_usuario|count_not_null|3408 |\n",
      "|usuarios  |cod_usuario|count_null    |2162 |\n",
      "|vendas    |-          |row_count     |20000|\n",
      "|vendas    |cod_usuario|count_distinct|3397 |\n",
      "|vendas    |cod_usuario|count_not_null|20000|\n",
      "|vendas    |cod_usuario|count_null    |0    |\n",
      "+----------+-----------+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data Profiling\n",
    "q(\"\"\"\n",
    "    WITH profiling AS (\n",
    "        SELECT \n",
    "        'vendas' AS table_name,\n",
    "        '-' AS column_name,\n",
    "        'row_count' AS profiling,\n",
    "        COUNT(*) AS value\n",
    "        FROM vendas\n",
    "\n",
    "        UNION ALL \n",
    "\n",
    "        SELECT \n",
    "        'usuarios' AS table_name,\n",
    "        '-' AS column_name,\n",
    "        'row_count' AS profiling,\n",
    "        COUNT(*) AS value\n",
    "        FROM usuarios\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT \n",
    "        'vendas' AS table_name,\n",
    "        'cod_usuario' AS column_name,\n",
    "        'count_distinct' AS profiling,\n",
    "        COUNT(DISTINCT cod_usuario) AS value\n",
    "        FROM vendas\n",
    "        WHERE\n",
    "        'cod_usuario' IS NOT NULL\n",
    "\n",
    "        UNION ALL \n",
    "\n",
    "        SELECT \n",
    "        'usuarios' AS table_name,\n",
    "        'cod_usuario' AS column_name,\n",
    "        'count_distinct' AS profiling,\n",
    "        COUNT(DISTINCT cod_usuario) AS value\n",
    "        FROM usuarios\n",
    "        WHERE\n",
    "        'cod_usuario' IS NOT NULL\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "        'usuarios' AS table_name,\n",
    "        'cod_usuario' AS column_name,\n",
    "        'count_null' AS profiling,\n",
    "        SUM(CASE WHEN ISNULL(cod_usuario) is true THEN 1 ELSE 0 END) AS value\n",
    "        FROM usuarios\n",
    "        GROUP BY \n",
    "        'vendas',\n",
    "        'column_name',\n",
    "        'count_null'\n",
    "\n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "        'vendas' AS table_name,\n",
    "        'cod_usuario' AS column_name,\n",
    "        'count_null' AS profiling,\n",
    "        SUM(CASE WHEN ISNULL(cod_usuario) is true THEN 1 ELSE 0 END) AS value\n",
    "        FROM vendas\n",
    "        GROUP BY \n",
    "        'vendas',\n",
    "        'column_name',\n",
    "        'count_null'\n",
    "\n",
    "\n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "            'usuarios' AS table_name,\n",
    "            'cod_usuario' AS column_name,\n",
    "            'count_not_null' AS profiling,\n",
    "            SUM(CASE WHEN ISNULL(cod_usuario) is true THEN 0 ELSE 1 END) AS value\n",
    "        FROM \n",
    "            usuarios\n",
    "        GROUP BY \n",
    "            'vendas',\n",
    "            'column_name',\n",
    "            'count_not_null'\n",
    "\n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "            'vendas' AS table_name,\n",
    "            'cod_usuario' AS column_name,\n",
    "            'count_not_null' AS profiling,\n",
    "            SUM(CASE WHEN ISNULL(cod_usuario) is true THEN 0 ELSE 1 END) AS value\n",
    "        FROM \n",
    "            vendas\n",
    "        GROUP BY \n",
    "            'vendas',\n",
    "            'column_name',\n",
    "            'count_not_null'\n",
    "    )\n",
    "    SELECT * FROM profiling ORDER BY table_name, column_name, profiling;\n",
    "    ;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Data Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_tabela_sql(nome_tabela, query, export_dir):\n",
    "    df = spark.sql(query)\n",
    "    pd = df.toPandas()\n",
    "    pd.to_csv(f\"{export_dir}/{nome_tabela}.csv\", index=False)\n",
    "    print(f'Tabela: [{nome_tabela}] exportada com sucesso para [{export_dir}/{nome_tabela}.csv]')\n",
    "    df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela: [usuarios] exportada com sucesso para [bases_limpas/usuarios.csv]\n"
     ]
    }
   ],
   "source": [
    "# Tabela Usuários\n",
    "query = (\"\"\"\n",
    "    WITH\n",
    "    tab_usuarios_not_null AS (\n",
    "        SELECT \n",
    "              usuarios.cod_usuario\n",
    "            , usuarios.data_cadastro\n",
    "            , usuarios.faixa_etaria\n",
    "            , usuarios.cidade\n",
    "            , usuarios.estado\n",
    "\n",
    "        FROM \n",
    "            usuarios \n",
    "        WHERE \n",
    "            cod_usuario IS NOT NULL\n",
    "    ),\n",
    "    tab_usuarios_duplicated AS (\n",
    "        SELECT\n",
    "             cod_usuario\n",
    "            ,COUNT(cod_usuario) AS count_cod_usuario\n",
    "        FROM \n",
    "            tab_usuarios_not_null\n",
    "        GROUP BY \n",
    "            cod_usuario\n",
    "        HAVING\n",
    "            COUNT(cod_usuario) > 1\n",
    "    )\n",
    "\n",
    "    SELECT \n",
    "          tab_usuarios_not_null.cod_usuario\n",
    "        , tab_usuarios_not_null.data_cadastro\n",
    "        , tab_usuarios_not_null.faixa_etaria\n",
    "        , tab_usuarios_not_null.cidade\n",
    "        , tab_usuarios_not_null.estado\n",
    "    FROM \n",
    "        tab_usuarios_not_null\n",
    "        LEFT JOIN tab_usuarios_duplicated ON tab_usuarios_not_null.cod_usuario = tab_usuarios_duplicated.cod_usuario\n",
    "    WHERE\n",
    "        tab_usuarios_duplicated.cod_usuario IS NULL\n",
    "    ;\n",
    "\"\"\")\n",
    "\n",
    "# Chamando a função\n",
    "limpa_tabela_sql('usuarios', query , 'bases_limpas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela: [vendas] exportada com sucesso para [bases_limpas/vendas.csv]\n"
     ]
    }
   ],
   "source": [
    "# Tabela Vendas\n",
    "query = (\"\"\"                \n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        vendas\n",
    "    ;\n",
    "\"\"\")\n",
    "\n",
    "# Chamando a função\n",
    "limpa_tabela_sql('vendas', query , 'bases_limpas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela: [produtos] exportada com sucesso para [bases_limpas/produtos.csv]\n"
     ]
    }
   ],
   "source": [
    "# Tabela Produtos\n",
    "query = (\"\"\"                \n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        produtos\n",
    "    ;\n",
    "\"\"\")\n",
    "\n",
    "# Chamando a função\n",
    "limpa_tabela_sql('produtos', query , 'bases_limpas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios = cria_tabela(\"bases_limpas/usuarios.csv\", \"usuarios\")\n",
    "produtos = cria_tabela(\"bases_limpas/produtos.csv\", \"produtos\")\n",
    "vendas = cria_tabela(\"bases_limpas/vendas.csv\", \"vendas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|3404    |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conferindo a Tabela de Usuários após o Data Cleansing\n",
    "q(\"\"\"\n",
    "SELECT \n",
    "        COUNT(*)\n",
    "        FROM usuarios\n",
    "        order by 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+------------------------------------+------------------------------------+\n",
      "|qt_cod_usuario_tab_vendas_not_null|qt_cod_usuario_tab_usuarios_not_null|qt_match_cod_usuario_vendas_usuarios|\n",
      "+----------------------------------+------------------------------------+------------------------------------+\n",
      "|3397                              |3404                                |66                                  |\n",
      "+----------------------------------+------------------------------------+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Correspondencia entre as tabelas Usuários e Vendas\n",
    "q(\"\"\"\n",
    "    WITH \n",
    "    tab_vendas_distinct_usuarios AS (\n",
    "        SELECT DISTINCT cod_usuario FROM vendas\n",
    "    ),\n",
    "    tab_usuarios_distinct_usuarios AS (\n",
    "        SELECT DISTINCT cod_usuario FROM usuarios\n",
    "    )\n",
    "    ,\n",
    "    join_vendas_usuarios AS (\n",
    "        SELECT \n",
    "              tab_vendas_distinct_usuarios.cod_usuario AS vendas_cod_usuario\n",
    "            , tab_usuarios_distinct_usuarios.cod_usuario AS usuarios_cod_usuario\n",
    "        FROM \n",
    "            tab_vendas_distinct_usuarios\n",
    "            FULL OUTER JOIN tab_usuarios_distinct_usuarios ON tab_vendas_distinct_usuarios.cod_usuario = tab_usuarios_distinct_usuarios.cod_usuario\n",
    "    )\n",
    "    \n",
    "    SELECT\n",
    "        -- count(*)\n",
    "         SUM(CASE WHEN ISNULL(vendas_cod_usuario) IS true THEN 0 ELSE 1 END) AS qt_cod_usuario_tab_vendas_not_null\n",
    "        ,SUM(CASE WHEN ISNULL(usuarios_cod_usuario) IS true THEN 0 ELSE 1 END) AS qt_cod_usuario_tab_usuarios_not_null\n",
    "        ,SUM(CASE WHEN vendas_cod_usuario = usuarios_cod_usuario IS true THEN 1 ELSE 0 END) AS qt_match_cod_usuario_vendas_usuarios\n",
    "        -- ** ENTENDER ISSO: \n",
    "        -- ,SUM(IFNULL(vendas_cod_usuario,1)) AS qt_vendas_cod_usuario_not_null\n",
    "        -- ,SUM(NVL(usuarios_cod_usuario,1)) AS qt_usuarios_cod_usuario_not_null\n",
    "    FROM\n",
    "        join_vendas_usuarios\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Perguntas sobre os dados\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kxzvs2rVoxGk"
   },
   "source": [
    "1) Qual foi a quantidade de vendas nos estados de Minas Gerais e São Paulo para cada ano e mês?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "eLe62-JehCDO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|estado      |ano |jan|fev|mar|abr|mai|jun|jul|ago|set|out|nov|dez|\n",
      "+------------+----+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|Minas Gerais|2018|-  |-  |-  |-  |-  |10 |-  |16 |-  |20 |10 |39 |\n",
      "|Minas Gerais|2019|20 |2  |-  |26 |11 |1  |14 |15 |27 |3  |1  |25 |\n",
      "|Minas Gerais|2020|8  |10 |14 |1  |44 |18 |30 |-  |44 |8  |43 |18 |\n",
      "|Minas Gerais|2021|21 |75 |6  |58 |22 |16 |61 |-  |-  |-  |-  |-  |\n",
      "|São Paulo   |2018|-  |-  |-  |-  |-  |-  |9  |-  |-  |12 |-  |-  |\n",
      "|São Paulo   |2019|-  |-  |-  |-  |-  |10 |-  |17 |-  |-  |-  |-  |\n",
      "|São Paulo   |2020|6  |-  |1  |9  |-  |13 |-  |-  |22 |41 |-  |-  |\n",
      "|São Paulo   |2021|-  |15 |1  |28 |22 |56 |96 |-  |-  |-  |-  |-  |\n",
      "+------------+----+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q(\"\"\"\n",
    "    WITH \n",
    "    qtd_vendas_estado AS (\n",
    "        SELECT \n",
    "            usuarios.estado,\n",
    "            DATE_FORMAT(vendas.data_compra,'y') as ano,\n",
    "            DATE_FORMAT(vendas.data_compra,'MM') as mes,\n",
    "            SUM(vendas.quantidade) as qt_vendas\n",
    "        FROM \n",
    "            vendas\n",
    "            LEFT JOIN usuarios ON usuarios.cod_usuario = vendas.cod_usuario\n",
    "        WHERE \n",
    "            usuarios.estado IN ('Minas Gerais','São Paulo')\n",
    "        GROUP BY \n",
    "            usuarios.estado,\n",
    "            DATE_FORMAT(vendas.data_compra,'y'),\n",
    "            DATE_FORMAT(vendas.data_compra,'MM')\n",
    "        HAVING\n",
    "            DATE_FORMAT(vendas.data_compra,'y') IS NOT NULL\n",
    "            OR\n",
    "            DATE_FORMAT(vendas.data_compra,'y') IS NOT NULL\n",
    "    )\n",
    "    \n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        qtd_vendas_estado\n",
    "        PIVOT (\n",
    "            IFNULL(SUM(qtd_vendas_estado.qt_vendas),'-')\n",
    "            FOR mes IN ('01' AS jan, \n",
    "                        '02' AS fev,\n",
    "                        '03' AS mar,\n",
    "                        '04' AS abr,\n",
    "                        '05' AS mai,\n",
    "                        '06' AS jun,\n",
    "                        '07' AS jul,\n",
    "                        '08' AS ago,\n",
    "                        '09' AS set,\n",
    "                        '10' AS out,\n",
    "                        '11' AS nov,\n",
    "                        '12' AS dez)\n",
    "        )\n",
    "    ORDER BY\n",
    "    1 , 2\n",
    "    ;        \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzD4NiqHplgI"
   },
   "source": [
    "2) Quais são os usuários por Estado que mais compraram em todo o período analisado e qual foi o número de compras realizadas, a quantidade total de itens comprados e valor total pago por usuário?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "bVV3Gnthp5hT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------------------+------------------------------+--------------------+--------------------------+\n",
      "|estado             |cod_usuario|count_compras_realizadas|sum_quantidade_items_comprados|sum_valor_total_pago|data_processamento        |\n",
      "+-------------------+-----------+------------------------+------------------------------+--------------------+--------------------------+\n",
      "|Amapá              |2186       |7                       |61                            |51359.34            |2022-07-31 11:43:08.317648|\n",
      "|Bahia              |466        |4                       |33                            |13613.89            |2022-07-31 11:43:08.317648|\n",
      "|Ceará              |1787       |8                       |79                            |121494.67           |2022-07-31 11:43:08.317648|\n",
      "|Goiás              |1878       |4                       |54                            |96862.10            |2022-07-31 11:43:08.317648|\n",
      "|Maranhão           |191        |7                       |69                            |26216.35            |2022-07-31 11:43:08.317648|\n",
      "|Mato Grosso        |1192       |7                       |76                            |16001.50            |2022-07-31 11:43:08.317648|\n",
      "|Mato Grosso do Sul |2492       |3                       |20                            |17998.00            |2022-07-31 11:43:08.317648|\n",
      "|Minas Gerais       |2903       |4                       |25                            |8965.17             |2022-07-31 11:43:08.317648|\n",
      "|Paraná             |2392       |6                       |42                            |41412.09            |2022-07-31 11:43:08.317648|\n",
      "|Paraíba            |1796       |3                       |51                            |54689.70            |2022-07-31 11:43:08.317648|\n",
      "|Pernambuco         |2669       |7                       |56                            |37119.00            |2022-07-31 11:43:08.317648|\n",
      "|Piauí              |2441       |5                       |33                            |40866.19            |2022-07-31 11:43:08.317648|\n",
      "|Rio Grande do Norte|185        |2                       |29                            |1327.10             |2022-07-31 11:43:08.317648|\n",
      "|Rio Grande do Sul  |1696       |6                       |24                            |1517.27             |2022-07-31 11:43:08.317648|\n",
      "|Santa Catarina     |2274       |2                       |11                            |1968.70             |2022-07-31 11:43:08.317648|\n",
      "|São Paulo          |1676       |5                       |44                            |18591.30            |2022-07-31 11:43:08.317648|\n",
      "|Tocantins          |156        |3                       |15                            |12910.47            |2022-07-31 11:43:08.317648|\n",
      "+-------------------+-----------+------------------------+------------------------------+--------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q(\"\"\"\n",
    "    WITH \n",
    "    \n",
    "    -- Inicio: Maiores compradores por estado -- \n",
    "    q010_vendas_usuario_estado AS (\n",
    "        SELECT \n",
    "            usuarios.estado,\n",
    "            usuarios.cod_usuario,\n",
    "            SUM(vendas.quantidade) AS qt_vendas\n",
    "        FROM \n",
    "            vendas\n",
    "            LEFT JOIN usuarios ON usuarios.cod_usuario = vendas.cod_usuario\n",
    "        GROUP BY \n",
    "            usuarios.estado,\n",
    "            usuarios.cod_usuario\n",
    "        HAVING\n",
    "            SUM(vendas.quantidade) IS NOT NULL\n",
    "    ),\n",
    "    \n",
    "    q011_rank_vendas_usuario_estado AS (\n",
    "        SELECT \n",
    "            q010.estado,\n",
    "            q010.cod_usuario,\n",
    "            q010.qt_vendas,\n",
    "            RANK() OVER (PARTITION BY q010.estado\n",
    "                             ORDER BY q010.estado, q010.qt_vendas\n",
    "                        ) AS classificacao\n",
    "        FROM \n",
    "            q010_vendas_usuario_estado AS q010\n",
    "    ),\n",
    "\n",
    "    q012_maiores_compradores_por_estado AS (\n",
    "        SELECT \n",
    "            q011.estado,\n",
    "            q011.cod_usuario,\n",
    "            q011.qt_vendas,\n",
    "            q011.classificacao\n",
    "        FROM \n",
    "            q011_rank_vendas_usuario_estado AS q011\n",
    "        WHERE\n",
    "            q011.classificacao = 1\n",
    "    ),    \n",
    "    -- Fim : Maiores compradores por estado -- \n",
    "    \n",
    "    \n",
    "    -- Inicio: Quantidade de vendas por usuário -- \n",
    "    q020_vendas_por_usuario AS (\n",
    "        SELECT \n",
    "            usuarios.estado,\n",
    "            vendas.cod_usuario,\n",
    "            COUNT(vendas.data_compra) AS count_compras_realizadas,\n",
    "            SUM(vendas.quantidade) AS sum_quantidade_items_comprados,\n",
    "            CAST(SUM(vendas.valor) AS DECIMAL(20,2)) as sum_valor_total_pago\n",
    "        FROM \n",
    "            vendas\n",
    "            LEFT JOIN usuarios ON vendas.cod_usuario = usuarios.cod_usuario\n",
    "        GROUP BY\n",
    "            usuarios.estado,\n",
    "            vendas.cod_usuario\n",
    "    )\n",
    "    -- Fim: Quantidade de vendas por usuario -- \n",
    "    \n",
    "    -- Tabela Final -- \n",
    "    SELECT \n",
    "        q012.estado,\n",
    "        q012.cod_usuario,\n",
    "        q020.count_compras_realizadas,\n",
    "        q020.sum_quantidade_items_comprados,\n",
    "        q020.sum_valor_total_pago,\n",
    "        data_processamento\n",
    "    FROM \n",
    "        q012_maiores_compradores_por_estado AS q012\n",
    "        LEFT JOIN q020_vendas_por_usuario   AS q020 ON q012.cod_usuario = q020.cod_usuario AND q012.estado = q020.estado,\n",
    "        (SELECT NOW() as data_processamento) \n",
    "    WHERE \n",
    "        q012.estado IS NOT NULL\n",
    "    ORDER BY \n",
    "        1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx53Cl5Xp6TV"
   },
   "source": [
    "3) Quais são os usuários que não fizeram nenhuma compra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "POtsi6dPq9-K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------+--------------------------+\n",
      "|cod_usuario|quantidade_total_clientes_sem_compra|data_processamento        |\n",
      "+-----------+------------------------------------+--------------------------+\n",
      "|19984      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|25517      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|41409      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|68090      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|87120      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|195413     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|200379     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|219523     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|246097     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|362827     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|371765     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|417190     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|485130     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|91785      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|67782      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|90817      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|18654      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|76143      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|54264      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|69048      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|63155      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|18800      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|22521      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|5614       |3338                                |2022-07-31 05:30:05.853347|\n",
      "|22188      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|50732      |3338                                |2022-07-31 05:30:05.853347|\n",
      "|149257     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|206380     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|221801     |3338                                |2022-07-31 05:30:05.853347|\n",
      "|224325     |3338                                |2022-07-31 05:30:05.853347|\n",
      "+-----------+------------------------------------+--------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q(\"\"\"\n",
    "    WITH \n",
    "    -- q01 - Inicio - Quantidade de vendas por estado\n",
    "    q01_qtd_vendas_estado AS (\n",
    "        SELECT \n",
    "            usuarios.cod_usuario\n",
    "        FROM \n",
    "            usuarios\n",
    "            LEFT ANTI JOIN vendas ON usuarios.cod_usuario = vendas.cod_usuario\n",
    "        GROUP BY \n",
    "            usuarios.cod_usuario\n",
    "    ),\n",
    "    -- q01 - Final - Quantidade de vendas por estado\n",
    "    \n",
    "    -- q99 - Inicio - Metadado\n",
    "    q99_metadado AS (\n",
    "        SELECT NOW() AS data_processamento\n",
    "    )\n",
    "    -- q99 - Final - Metadado\n",
    "    \n",
    "    -- Tabela Final --        \n",
    "    SELECT \n",
    "          q01.cod_usuario\n",
    "        , COUNT(q01.cod_usuario) OVER (PARTITION BY q99.data_processamento) AS quantidade_total_clientes_sem_compra\n",
    "        , q99.data_processamento\n",
    "    FROM \n",
    "        q01_qtd_vendas_estado AS q01,\n",
    "        q99_metadado AS q99\n",
    "    ;        \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMfPmlvJq-vq"
   },
   "source": [
    "4) Qual é o ticket médio (média de valor gasto) e o número total de usuários que fizeram pelo menos uma compra por faixa etária?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2wmU9pLbrMg3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+------------+--------------------------+\n",
      "|faixa_etaria      |qtd_usuarios_compraram|ticket_medio|data_processamento        |\n",
      "+------------------+----------------------+------------+--------------------------+\n",
      "|Entre 10 a 15 anos|7                     |8890.13     |2022-07-31 05:30:13.691028|\n",
      "|Entre 16 a 21 anos|11                    |12725.95    |2022-07-31 05:30:13.691028|\n",
      "|Entre 22 a 27 anos|10                    |12203.02    |2022-07-31 05:30:13.691028|\n",
      "|Entre 28 a 36 anos|9                     |8233.04     |2022-07-31 05:30:13.691028|\n",
      "|Entre 37 a 49 anos|6                     |16727.19    |2022-07-31 05:30:13.691028|\n",
      "|Entre 50 a 61 anos|12                    |10849.48    |2022-07-31 05:30:13.691028|\n",
      "|Entre 62 a 70 anos|7                     |10012.63    |2022-07-31 05:30:13.691028|\n",
      "|Mais de 70 anos   |4                     |11303.10    |2022-07-31 05:30:13.691028|\n",
      "+------------------+----------------------+------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A tabela de usuários só tem correspondencia na base de vendas para 66 usuários (~1.93% dos usuários únicos).\n",
    "# Por isso é inviável fazer estimativas por 'faixa etária'.\n",
    "# No entanto, podemos extrair a informação para os dados disponíveis, levando em consideração os usuários que possuem a faixa etária descrita.\n",
    "\n",
    "q(\"\"\"\n",
    "    WITH \n",
    "    -- q01 - Inicio - Usuarios, Compras\n",
    "    q01_usuarios_compras AS (\n",
    "        SELECT  \n",
    "             vendas.cod_usuario\n",
    "            ,usuarios.faixa_etaria \n",
    "            ,vendas.quantidade\n",
    "            ,vendas.valor\n",
    "        FROM \n",
    "            vendas\n",
    "            LEFT JOIN usuarios ON usuarios.cod_usuario = vendas.cod_usuario\n",
    "    ),\n",
    "    -- q01 - Final - Usuarios, Compras\n",
    "    \n",
    "    -- q99 - Inicio - Metadado\n",
    "    q99_metadado AS (\n",
    "        SELECT NOW() AS data_processamento\n",
    "    )\n",
    "    -- q99 - Final - Metadado\n",
    "      \n",
    "    -- Tabela Final --\n",
    "    SELECT \n",
    "          q01.faixa_etaria\n",
    "         ,COUNT(DISTINCT q01.cod_usuario) AS qtd_usuarios_compraram\n",
    "         ,CAST(AVG(q01.valor) AS DECIMAL(10,2)) AS ticket_medio\n",
    "         ,q99.data_processamento\n",
    "    FROM \n",
    "         q01_usuarios_compras AS q01\n",
    "        ,q99_metadado AS q99\n",
    "    WHERE \n",
    "        faixa_etaria IS NOT NULL\n",
    "    GROUP BY\n",
    "         q01.faixa_etaria\n",
    "        ,q99.data_processamento\n",
    "    ORDER BY \n",
    "        q01.faixa_etaria\n",
    "    ;        \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3zzx4TnTJ0ck"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsxnKyHTr9ZQ"
   },
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHTFrsFRKENk"
   },
   "source": [
    "**setup**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ExrbmwGPJ74k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘bases_teste’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1039  100  1039    0     0   8725      0 --:--:-- --:--:-- --:--:--  8805\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  533k  100  533k    0     0  2507k      0 --:--:-- --:--:-- --:--:-- 2518k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211k  100  211k    0     0   696k      0 --:--:-- --:--:-- --:--:--  694k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir bases_teste\n",
    "curl https://raw.githubusercontent.com/A3Data/bases_testes/main/bases_teste/produtos.csv -o bases_teste/produtos.csv\n",
    "curl https://raw.githubusercontent.com/A3Data/bases_testes/main/bases_teste/vendas.csv -o bases_teste/vendas.csv\n",
    "curl https://raw.githubusercontent.com/A3Data/bases_testes/main/bases_teste/usuarios.csv -o bases_teste/usuarios.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1iMZB37mJ74k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/31 04:35:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/31 04:35:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Setup Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"AtividadeSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5wjdDd3tJ74l"
   },
   "outputs": [],
   "source": [
    "def cria_tabela(path, nome_tabela):\n",
    "    df = spark.read.csv(path, inferSchema=True, header=True)\n",
    "    df.createOrReplaceTempView(nome_tabela)\n",
    "    return df\n",
    "\n",
    "usuarios = cria_tabela(\"bases_teste/usuarios.csv\", \"usuarios\")\n",
    "produtos = cria_tabela(\"bases_teste/produtos.csv\", \"produtos\")\n",
    "vendas = cria_tabela(\"bases_teste/vendas.csv\", \"vendas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHCtQfrvKpWz"
   },
   "source": [
    "Responda às perguntas a seguir utilizando **Spark DATAFRAMES**.\n",
    "\n",
    "1) Qual foi o total de compras realizadas, o total de itens comprados e a receita total obtida em todo o período analisado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0CcQqjM3r-mq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cod_usuario: integer (nullable = true)\n",
      " |-- cod_produto: integer (nullable = true)\n",
      " |-- data_compra: timestamp (nullable = true)\n",
      " |-- quantidade: integer (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      "\n",
      "+---------------+--------------------+\n",
      "|sum(quantidade)|sum(valor)          |\n",
      "+---------------+--------------------+\n",
      "|209149         |2.1584900165999958E8|\n",
      "+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import avg, format_number, round\n",
    "\n",
    "# Schema 'vendas'\n",
    "vendas.printSchema()\n",
    "\n",
    "# Somas\n",
    "vendas.groupBy() \\\n",
    "    .sum(\"quantidade\", \"valor\") \\\n",
    "    .show(truncate=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVV0rIT8KzZ2"
   },
   "source": [
    "2) Quais são os 3 produtos mais comprados dos estados da região Sul e Sudeste, a quantidade de itens comprados, o valor total pago e a média de preço paga?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "JkX1ByRdLa5V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------+------------------+----------+-----------------+\n",
      "|estado      |cod_produto|sum_quantidade|sum_valor         |row_number|media_preco_pago |\n",
      "+------------+-----------+--------------+------------------+----------+-----------------+\n",
      "|Minas Gerais|16         |6             |30.0              |1         |5.0              |\n",
      "|Minas Gerais|11         |7             |349.29999999999995|2         |49.89999999999999|\n",
      "|Minas Gerais|13         |9             |89.1              |3         |9.899999999999999|\n",
      "|São Paulo   |9          |1             |389.1             |1         |389.1            |\n",
      "|São Paulo   |17         |2             |1168.2            |2         |584.1            |\n",
      "|São Paulo   |11         |6             |299.4             |3         |49.9             |\n",
      "+------------+-----------+--------------+------------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col\n",
    "\n",
    "\n",
    "# Join das Tabelas Vendas, Usuarios e Produtos\n",
    "df_vendas_usuarios_produtos = vendas.join(usuarios, (vendas.cod_usuario == usuarios.cod_usuario)) \\\n",
    "        .join(produtos, ['cod_produto'])\n",
    "\n",
    "# Agregação\n",
    "df_vendas_usuarios_produtos = df_vendas_usuarios_produtos.groupBy(\"estado\",\"cod_produto\") \\\n",
    "    .sum(\"quantidade\",\"valor\") \\\n",
    "    .withColumnRenamed(\"sum(quantidade)\", \"sum_quantidade\") \\\n",
    "    .withColumnRenamed(\"sum(valor)\", \"sum_valor\")\n",
    "\n",
    "# Classificação de Vendas por Estado e Produto\n",
    "windowSpec  = Window.partitionBy(\"estado\").orderBy(\"sum_quantidade\")\n",
    "\n",
    "regiao_sudeste = ['Espirito Santo', 'Minas Gerais', 'São Paulo', 'Rio de Janeiro']\n",
    "\n",
    "df_vendas_usuarios_produtos.withColumn(\"row_number\",row_number().over(windowSpec)) \\\n",
    "    .filter(col(\"estado\").isin(regiao_sudeste)) \\\n",
    "    .filter(col(\"row_number\") <= 3) \\\n",
    "    .withColumn('media_preco_pago', df_vendas_usuarios_produtos['sum_valor'] / (df_vendas_usuarios_produtos['sum_quantidade'])) \\\n",
    "    .show(n=10000, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CaldadHLbgm"
   },
   "source": [
    "3) Para cada produto, quantos usuários fizeram pelo menos uma compra desse produto e qual é o valor mínimo e máximo pago por eles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgwOymWOLqAB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUM8hfarLqy9"
   },
   "source": [
    "4) Aplique um desconto de 10% em todas as vendas dos usuários que fizeram pelo menos 3 compras de produtos na mesma categoria, a partir da 4ª compra realizada. Exiba apenas os usuários que terão o desconto aplicado, mantendo todas as compras, o valor original e o valor com o desconto aplicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "YEYCoeHlMGHl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------------+----------+--------+--------------------+--------------------+-------------+----------------+------------------+\n",
      "|cod_produto|cod_usuario|        data_compra|quantidade|   valor|        nome_produto|   categoria_produto|valor_produto|numero_da_compra|valor_com_desconto|\n",
      "+-----------+-----------+-------------------+----------+--------+--------------------+--------------------+-------------+----------------+------------------+\n",
      "|          1|          3|2021-07-20 00:00:00|         8| 36727.2|Notebook Asus Int...|          Tecnologia|       4590.9|               4|33054.479999999996|\n",
      "|          8|          6|2021-03-23 00:00:00|         2|  439.14| Cafeteira Nespresso|    Eletrodomesticos|       219.57|               4|           395.226|\n",
      "|          1|         16|2021-02-16 00:00:00|         9| 41318.1|Notebook Asus Int...|          Tecnologia|       4590.9|               4|          37186.29|\n",
      "|         17|         16|2021-05-23 00:00:00|         8|  4672.8|Monitor LG 19 pol...|          Tecnologia|        584.1|               5|           4205.52|\n",
      "|         18|         17|2021-07-21 00:00:00|        12|    94.8|Lenço umedecido T...| Produtos de limpeza|          7.9|               4|             85.32|\n",
      "|         18|         17|2021-07-30 00:00:00|        15|   118.5|Lenço umedecido T...| Produtos de limpeza|          7.9|               5|            106.65|\n",
      "|          7|         23|2020-07-08 00:00:00|        19|24709.31|Ar-condicionado 9...|    Casa e bem-estar|      1300.49|               4|         22238.379|\n",
      "|          6|         34|2021-07-28 00:00:00|         3|  2699.7|      Sofa 3 lugares|    Casa e bem-estar|        899.9|               4|           2429.73|\n",
      "|          6|         37|2021-07-10 00:00:00|         1|   899.9|      Sofa 3 lugares|    Casa e bem-estar|        899.9|               4|            809.91|\n",
      "|          1|         39|2020-11-17 00:00:00|        11| 50499.9|Notebook Asus Int...|          Tecnologia|       4590.9|               4|          45449.91|\n",
      "|         15|         41|2020-08-30 00:00:00|         8|   39.92|Alcool em Gel 70%...| Produtos de limpeza|         4.99|               4|35.928000000000004|\n",
      "|          7|         87|2021-07-27 00:00:00|        15|19507.35|Ar-condicionado 9...|    Casa e bem-estar|      1300.49|               4|17556.614999999998|\n",
      "|         18|        101|2021-06-11 00:00:00|         1|     7.9|Lenço umedecido T...| Produtos de limpeza|          7.9|               4|              7.11|\n",
      "|          5|        106|2020-10-16 00:00:00|        15|  6555.0|   Escrivaninha em L|Material de escri...|        437.0|               4|            5899.5|\n",
      "|         16|        123|2021-07-20 00:00:00|         2|    10.0|Biscoito Chocolic...|           Alimentos|          5.0|               4|               9.0|\n",
      "|          6|        132|2020-11-17 00:00:00|        18| 16198.2|      Sofa 3 lugares|    Casa e bem-estar|        899.9|               4|14578.380000000001|\n",
      "|         17|        132|2021-01-16 00:00:00|        17|  9929.7|Monitor LG 19 pol...|          Tecnologia|        584.1|               4| 8936.730000000001|\n",
      "|         18|        166|2021-07-27 00:00:00|        20|   158.0|Lenço umedecido T...| Produtos de limpeza|          7.9|               4|             142.2|\n",
      "|         21|        184|2021-07-28 00:00:00|         3| 17997.3|     SPA Intel 700 L|               Lazer|       5999.1|               4|          16197.57|\n",
      "|         15|        203|2021-06-10 00:00:00|        15|   74.85|Alcool em Gel 70%...| Produtos de limpeza|         4.99|               4|            67.365|\n",
      "+-----------+-----------+-------------------+----------+--------+--------------------+--------------------+-------------+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col, when\n",
    "\n",
    "\n",
    "# Join das Tabelas Vendas e Produtos\n",
    "df_vendas_produtos = vendas.join(produtos, ['cod_produto'])\n",
    "\n",
    "# Classificação das compras por usuario e categoria\n",
    "windowSpec  = Window.partitionBy(\"cod_usuario\",\"categoria_produto\").orderBy(\"data_compra\")\n",
    "df_vendas_produtos = df_vendas_produtos.withColumn(\"numero_da_compra\",row_number().over(windowSpec))\n",
    "\n",
    "# Calcula 10% de desconto a partir da 4ª compra\n",
    "df_vendas_produtos = df_vendas_produtos.withColumn(\"valor_com_desconto\", when(df_vendas_produtos.numero_da_compra > 3, df_vendas_produtos.valor - df_vendas_produtos.valor * 0.1) \\\n",
    "        .otherwise(df_vendas_produtos.valor))\n",
    "\n",
    "# Filtra os resultados \n",
    "df_vendas_produtos = df_vendas_produtos.filter(col(\"numero_da_compra\") > 3 )\n",
    "\n",
    "# Exibe o resultado\n",
    "df_vendas_produtos.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndROlUqgMHxn"
   },
   "source": [
    "# FIM!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Teste Engenharia de Dados v2_2 - modelo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "696261bc91c04e4df3605ce73073fde8bd8da3b42592b8c5d8186de2e507249e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
